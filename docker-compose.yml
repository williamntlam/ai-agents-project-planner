version: '3.8'

services:
  # PostgreSQL with pgvector extension
  pgvector:
    image: pgvector/pgvector:pg16
    container_name: pgvector
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-vector_db}
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - pgvector_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    command: >
      postgres
      -c shared_buffers=256MB
      -c max_connections=200
      -c checkpoint_timeout=15min
      -c wal_level=replica
      -c max_wal_size=1GB
      -c min_wal_size=80MB
    networks:
      - etl_network

  # ETL Pipeline
  etl_pipeline:
    build:
      context: .
      dockerfile: etl_pipeline/Dockerfile
    container_name: etl_pipeline
    restart: "no"  # Don't auto-restart (run once)
    environment:
      # Database connection
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@pgvector:5432/${POSTGRES_DB:-vector_db}
      
      # OpenAI API key
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      
      # ETL environment
      ETL_ENV: ${ETL_ENV:-local}
      
      # Python settings
      PYTHONUNBUFFERED: 1
      PYTHONPATH: /app
    volumes:
      # Mount data directory (read-only for safety)
      - ./data:/app/data:ro
      
      # Mount config directory
      - ./etl_pipeline/config:/app/etl_pipeline/config:ro
      
      # Mount logs directory (write access)
      - ./logs:/app/logs
      
      # Optional: Mount .env file
      - ./.env:/app/.env:ro
    depends_on:
      pgvector:
        condition: service_healthy
    networks:
      - etl_network
    # Override command if needed
    # command: ["python", "-m", "etl_pipeline.main", "--env", "prod", "--verbose"]

volumes:
  pgvector_data:
    driver: local

networks:
  etl_network:
    driver: bridge

